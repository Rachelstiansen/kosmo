{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11280ebb",
   "metadata": {},
   "source": [
    "<div align=\"center\"><h1>\n",
    "Modeling The CMB Frequency Spectrum with COBE/FIRAS\n",
    "</h1>\n",
    "<h2>By: Katherine Lee</h2>\n",
    "</div>\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f955f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import emcee as mc\n",
    "from corner import corner\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy import constants as const\n",
    "from astropy.table import QTable\n",
    "\n",
    "from IPython.display import display, Math\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from astropy.visualization import quantity_support\n",
    "\n",
    "quantity_support()\n",
    "set_matplotlib_formats('svg')\n",
    "from matplotlib import cm\n",
    "from cycler import cycler\n",
    "plt.rc('legend', frameon = False)\n",
    "plt.rc('figure', figsize = (7, 7/1.25))\n",
    "plt.rc('font', size = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10936c4e",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "We're using data from Table 4 of [Fixsen et. al. (1996)](https://articles.adsabs.harvard.edu/pdf/1996ApJ...473..576F), which consists of frequencies in cm$^{-1}$, as well as residuals, uncertainties, and a model of the Milky Way, all in kJy/sr. There is also an artificial monopole spectrum included, which is produced by adding a 2.725 K blackbody spectrum to the given residuals. This seems to be the current accepted value for T$_0$, although it is not the one actually reported in Fixsen et. al. (1996). \n",
    "\n",
    "It might be useful to make an alternate array of frequencies in s$^{-1}$, depending on how you plan on formatting your models, but is not technically necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a443d4c7-9c59-419d-8c67-d870468cf70f",
   "metadata": {},
   "source": [
    "First, let's read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9777ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "names = [\"freq\", \"monopole\", \"res\", \"sigma\", \"gal\"]\n",
    "tmp = pd.read_csv(\"https://lambda.gsfc.nasa.gov/data/cobe/firas/monopole_spec/firas_monopole_spec_v1.txt\", delim_whitespace = True, header = 0, skiprows = 17, names = names)\n",
    "unit_names = [\"cm-1\", \"MJy/sr\", \"kJy/sr\", \"kJy/sr\", \"kJy/sr\"]\n",
    "units = {names[i]:unit_names[i] for i in range(len(names))}\n",
    "firas = QTable.from_pandas(tmp, units = units)\n",
    "\n",
    "#make a version of the frequency in s-1\n",
    "firas_freq = firas[\"freq\"].to('GHz', equivalencies = u.spectral())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7b1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackbody(nu, T):\n",
    "    '''\n",
    "    Return standard CMB blackbody in MJy/sr\n",
    "    You can use astropy constants, i.e., c.k_B, and astropy units, u.sr, u.GHz, ec.\n",
    "    '''\n",
    "    T = ...\n",
    "    x = const.h * const.c * firas_freq / (const.k_B * T)\n",
    "    S_nu = 2 * const.h * const.c**2 * firas_freq**3 / (np.exp(x + const.mu) - 1)\n",
    "    \n",
    "    return S_nu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7873f5-5158-44d0-8c7b-1221eed6c58c",
   "metadata": {},
   "source": [
    "and plot the monopole data, with the quoted $T_0$ blackbody to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a239b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(firas_freq, firas[\"monopole\"], yerr = firas[\"sigma\"], fmt = 'k.')\n",
    "plt.plot(firas_freq.to(\"GHz\"), blackbody(firas_freq, T), color = 'xkcd:turquoise', ls = \"--\", label = \"fit\")\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(\"Intensity (MJy/sr)\")\n",
    "plt.title(\"Monopole temperature\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7bff0c",
   "metadata": {},
   "source": [
    "### Consistency check 1\n",
    "\n",
    "The error bars are smaller than the fit line.\n",
    "\n",
    "1. Plot the error bars scaled by a sufficiently large factor.\n",
    "2. Note the frequencies where the error bars are noticeably larger. What could cause this relative increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc422be",
   "metadata": {},
   "source": [
    "## 2. Fitting the data\n",
    "\n",
    "How do we know that this temperature is actually the most likely value? We can use `emcee` to reproduce the temperature used to generate the monopole data. If you've never used `emcee` before, a tutorial can be found in the [documentation](https://emcee.readthedocs.io/en/stable/tutorials/line/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924bb57-6db8-4135-b92a-a48e3974c578",
   "metadata": {},
   "source": [
    "We will first define the log-likelihood function for our model assessment. This will be passed into `emcee`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b98098",
   "metadata": {},
   "source": [
    "### Consistency check 2\n",
    "\n",
    "The blackbody spectrum is given mathematically by\n",
    "$$\n",
    "S_\\nu(T)=\\frac{2h\\nu^3}{c^2}\\frac1{e^{h\\nu/kT}-1}.\n",
    "$$\n",
    "Assuming that the noise $S_\\mathrm{err}$ describes Gaussian noise, such that\n",
    "$$\n",
    "d_\\nu=S_\\nu(T) + n_\\nu\n",
    "$$\n",
    "where $n_\\nu\\sim\\mathcal N(0,S_\\mathrm{err}^2)$, derive the log-likelihood and code it in the next section.\n",
    "\n",
    "\n",
    "Potential pitfalls:\n",
    "\n",
    "1. Make sure that $h\\nu/kT$ is unitless.\n",
    "2. Make sure that the model and the data have the same units, MJy/sr.\n",
    "3. $e^{h\\nu/kT}-1$ can be very close to zero. The numpy function `np.expm1` may be useful for numerical stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae31f5",
   "metadata": {},
   "source": [
    "In order to assess the goodness of fit, you need to estimate how model differs from the data, relative to the frequency. Essentially, is $d_\\nu -S_\\nu(T)$ given by a normal distribution? As a gentle reminder, a single data point has the probabili**Write down the expression for the likelihood, assuming that all of the data points are given, then code it up in the next code block.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c10d00",
   "metadata": {},
   "source": [
    "**The answer is...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84069fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log likelihood function:\n",
    "def log_LBB(T, nu, S, Serr):\n",
    "    #T is temperature in Kelvin\n",
    "    #nu is frequency in s-1\n",
    "    #S is the monopole spectrum in MJy/sr\n",
    "    #and Serr is the error in kJy/sr\n",
    "    \n",
    "    return log_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15320c-580d-4941-b791-898cb0b9aece",
   "metadata": {},
   "source": [
    "Then we will run the `emcee` chain! We will need to define a few things to get `emcee` to run:\n",
    "A random seed, the chain length, as well as a initial position for the sampler to explore from, as well as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b74b914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run mcmc\n",
    "np.random.seed(42)\n",
    "chain_len = 3000\n",
    "T_ini = 2.7*u.K\n",
    "# Draw initial positions for each of the walkers\n",
    "pos = T_ini + 1e-3*np.random.randn(32, 1)*u.K\n",
    "nwalkers, ndim = pos.shape\n",
    "\n",
    "# Run the sampler\n",
    "sampler = mc.EnsembleSampler(nwalkers, ndim, log_LBB, args = (firas_freq, firas[\"monopole\"], firas[\"sigma\"]))\n",
    "sampler.run_mcmc(pos, chain_len, progress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f82baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all samples:\n",
    "samples = sampler.get_chain()\n",
    "\n",
    "#plot samples over time\n",
    "plt.figure()\n",
    "plt.plot(samples[:, :, 0], \"k\", alpha = 0.3)\n",
    "plt.ylabel(\"T\")\n",
    "plt.xlabel(\"sample number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c32d7a9",
   "metadata": {},
   "source": [
    "## Consistency check 3\n",
    "\n",
    "The autocorrelation length (see https://emcee.readthedocs.io/en/stable/tutorials/autocorr/) is an estimate for how many samples must be separated by to be considered independent. Using the estimate of the autocorrelation length $\\tau$, see how many integer multiples of $\\tau$ are necessary to see if the chain is truly burned in.\n",
    "\n",
    "If the chain is truly converged, a good rule of thumb is that it should look like a \"hairy caterpillar\". Comment on whether this seems like a good metric, and if you agree with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e2a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get autocorrelation time:\n",
    "tau = sampler.get_autocorr_time()\n",
    "print(tau)\n",
    "\n",
    "\n",
    "#plot samples over time\n",
    "plt.figure()\n",
    "plt.title('Burned in chain')\n",
    "plt.ylabel(\"T\")\n",
    "plt.xlabel(\"sample number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab275d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print final estimate\n",
    "flat_samples = sampler.get_chain(discard = , thin = int(tau), flat = True)\n",
    "T_mcmc = np.percentile(flat_samples[:, 0], [16, 50, 84])\n",
    "q = np.diff(T_mcmc)\n",
    "\n",
    "txt = \"\\mathrm{{{3}}} = {0:.6f}_{{-{1:.6f}}}^{{{2:.6f}}}\"\n",
    "txt = txt.format(T_mcmc[1], q[0], q[1], \"T\")\n",
    "display(Math(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc980fb2",
   "metadata": {},
   "source": [
    "## Consistency check 4\n",
    "\n",
    "Fixsen (2009) (https://ui.adsabs.harvard.edu/abs/2009ApJ...707..916F/abstract) is the widely-cited paper that contains the final temperature estimate of the FIRAS instrument. How does your result compare with these results? Comment on any notable differences, and posit a possible explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050849b0",
   "metadata": {},
   "source": [
    "#### Short answer\n",
    "\n",
    "\n",
    "*I believe that...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adff4f9",
   "metadata": {},
   "source": [
    "# Spectral Distortions\n",
    "\n",
    "Now, we'll use the residuals to sample the spectral distortions, or the differences between the FIRAS data and a pure blackbody spectrum. These spectral distortions originate from energy that has been injected into the early universe, causing the system to be at a slightly higher energy state than that of pure equilibrium. We use two different parameters to quantify these distortions: $\\mu$ and $y$. These represent energy injections from high-energy scattering events at higher redshifts, and Compton scattering at lower redshifts, respectively (Fixsen et. al. 1996). \n",
    "\n",
    "Sunyaev and Zeldovich (1970) state that the source of $\\mu$-type spectral distortions is that prior to recombination and decoupling, at redshifts between $10^5 < z < 3\\times 10^6$, \"bremsstrahlung processes are not able to maintain complete thermodynamic equilibrium between matter and radiation. Meanwhile the transfer of energy between electrons and photons due to scattering occurs sufficiently quickly for a Bose-Einstein distribution to be established.\" So basically, electrons and such are being excited at a high enough rate that the energy bound up in them can't be radiated away fast enough for the plasma to reach equilibrium, creating a chemical potential $\\mu$.\n",
    "\n",
    "According to Fixsen et. al. (1996), the effect of $y$-distortions is to produce \"a Comptonized spectrum, [i.e.] a mixture of blackbodies at a range of temperatures.\" These typically come into play at $z<10^5$, and Chluba (2005) implies that they can also be created after decoupling by the Sunyaev-Zeldovich effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dae0a9",
   "metadata": {},
   "source": [
    "### Consistency check 4\n",
    "\n",
    "At this point in the analysis, it is helpful to assume that we basically have the correct temperature, $T_0$, and any corrections will be small, and given by $\\Delta T$. This means that the data can be modeled as\n",
    "$$\n",
    "B_\\nu(T_0+\\Delta T)-B_\\nu(T_0)\\simeq\\,\\Delta T\n",
    "\\left.\\frac{\\partial B_\\nu}{\\partial T}\\right|_{T=T_0}\n",
    "$$\n",
    "\n",
    "Derive the spectrum of the deviations from the ideal blackbody, $\\partial B_\\nu/\\partial T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844507f3",
   "metadata": {},
   "source": [
    "*First, we...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fa972-edd4-4f10-98f0-65a056210375",
   "metadata": {},
   "source": [
    "Now we want to sample for any potential distortions in the spectrum, whether $\\mu$ or $y$ type. Again we'll need to define log-likelihood functions for the spectral distortion distributions. Before we do that, let us define functional forms for both of the distortion types, $\\mu$ and $y$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbbe62f",
   "metadata": {},
   "source": [
    "### Consistency check 5\n",
    "\n",
    "A $\\mu$-type distribution is equivalent to a Bose-Einstein distribution with chemical potential $\\mu$,\n",
    "$$\n",
    "I_\\nu^\\mathrm{BE}=\\frac{2h\\nu^3}{c^2}\\frac{1}{e^{x+\\mu}-1}\n",
    "$$\n",
    "where $x=h\\nu/kT$.\n",
    "\n",
    "Derive the first order correction, $I_\\nu^\\mathrm{SD,\\mu}=\\mu\\frac{\\partial I_\\nu}{\\partial \\mu}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2a6341",
   "metadata": {},
   "source": [
    "*We begin by...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840bc1da",
   "metadata": {},
   "source": [
    " \n",
    " A similar approach can be followed to separate $y$ distortion map, where the emission law is\n",
    " \n",
    " \n",
    "\\begin{equation}\n",
    "I_{\\nu}^{\\mathrm{SD},y} = yT_0 \\Big(x\\frac{\\exp{x}+1}{\\exp{x}-1}-4\\Big)\\frac{\\partial B_\\nu}{\\partial T}\\Big|_{T=T_0}.\"\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e6f206-90b8-4523-9746-67b679a2c75a",
   "metadata": {},
   "source": [
    "The above equations are the functions which we need to evaluate in order to fit for the spectral parameter. Let's do that now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bfcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dBdT(nu, T = 2.725*u.K):\n",
    "    #nu is frequency in s-1\n",
    "    x = const.h*nu/const.k_B/T\n",
    "    dBdT = \n",
    "    return dBdT\n",
    "\n",
    "\n",
    "def func_mu(nu, mu, T = 2.725):\n",
    "    #nu is frequency in s-1\n",
    "    #mu is dimensionless\n",
    "    #T is unitless or else emcee freaks out\n",
    "    T = T*u.K\n",
    "    x = const.h*nu/const.k_B/T\n",
    "    f = \n",
    "    return f\n",
    "    \n",
    "\n",
    "def func_y(nu, y, T = 2.725):\n",
    "    #nu is frequency in s-1\n",
    "    #y is dimensionless\n",
    "    #T is unitless or else emcee freaks out\n",
    "    T = T*u.K\n",
    "    x = const.h*nu/const.k_B/T\n",
    "    f = \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de3db5-382c-4b4f-905d-9b7a04644327",
   "metadata": {},
   "source": [
    "Define some likelihood functions here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b2a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Ly(theta, nu, Sres, Serr):\n",
    "    #nu is an array of frequencies in s-1\n",
    "    #Sres and Serr are the residual and error arrays in kJy/sr\n",
    "    y = theta\n",
    "    model = func_y(nu, y)\n",
    "    \n",
    "    log_L = \n",
    "    return log_L\n",
    "\n",
    "def log_Lmu(theta, nu, Sres, Serr):\n",
    "    mu = theta\n",
    "    model = func_mu(nu, mu)\n",
    "    \n",
    "    log_L = \n",
    "    return log_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80967fb7-f680-46bc-abb2-9e972471f2e6",
   "metadata": {},
   "source": [
    "Before we try sampling for each of the parameters ($T$, $\\mu$, $y$) together, let's do them one at a time. Now setting up `emcee` for $y$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96844fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mcmc for y:\n",
    "np.random.seed(42)\n",
    "chain_len = 2000\n",
    "y_ini = -1e-6\n",
    "pos_y = y_ini + 1e-6*np.random.randn(32, 1)\n",
    "nwalkers_y, ndim_y = pos_y.shape\n",
    "\n",
    "sampler_y = mc.EnsembleSampler(nwalkers_y, ndim_y, log_Ly, args = (firas_freq, firas[\"res\"], firas[\"sigma\"]))\n",
    "sampler_y.run_mcmc(pos_y, chain_len, progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3fb611-4ecd-4589-a901-85f43eb5b3fe",
   "metadata": {},
   "source": [
    "Now for $\\mu$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42c0b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_ini = -1e-5\n",
    "pos_mu = mu_ini + 1e-6*np.random.randn(32, 1)\n",
    "nwalkers_mu, ndim_mu = pos_mu.shape\n",
    "\n",
    "sampler_mu = mc.EnsembleSampler(nwalkers_mu, ndim_mu, log_Lmu, args = (firas_freq, firas[\"res\"], firas[\"sigma\"]))\n",
    "sampler_mu.run_mcmc(pos_mu, chain_len, progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8de032-1cbc-45bf-b5c0-b06795d3bdd1",
   "metadata": {},
   "source": [
    "Let's plot the chains to visualize convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41fa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get autocorrelation time:\n",
    "tau_y = \n",
    "tau_mu = \n",
    "print(tau_y, tau_mu)\n",
    "\n",
    "#get all samples:\n",
    "samples_y = \n",
    "samples_mu = \n",
    "#print(samples_y.shape, samples_mu.shape)\n",
    "\n",
    "#plot samples over time\n",
    "fig, axes = plt.subplots(sharex=True, nrows=2)\n",
    "axes[0].plot()\n",
    "axes[0].set_ylabel(r\"$y$\")\n",
    "axes[1].plot()\n",
    "axes[1].set_ylabel(r\"$\\mu$\")\n",
    "axes[1].set_xlabel(\"sample number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_samples_y = sampler_y.get_chain(discard = , thin = int(tau_y), flat = True)\n",
    "y_mcmc = np.percentile(flat_samples_y[:, 0], [16, 50, 84])\n",
    "q_y = np.diff(y_mcmc)\n",
    "\n",
    "flat_samples_mu = sampler_mu.get_chain(discard = , thin = int(tau_mu), flat = True)\n",
    "mu_mcmc = np.percentile(flat_samples_mu[:, 0], [16, 50, 84])\n",
    "q_mu = np.diff(mu_mcmc)\n",
    "\n",
    "txt = \"\\mathrm{{{3}}} = {0:.7f}_{{-{1:.6f}}}^{{{2:.6f}}}\"\n",
    "txt_y = txt.format(y_mcmc[1], q_y[0], q_y[1], \"y\")\n",
    "txt_mu = txt.format(mu_mcmc[1], q_mu[0], q_y[1], \"\\mu\")\n",
    "display(Math(txt_y))\n",
    "display(Math(txt_mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcae0fa8",
   "metadata": {},
   "source": [
    "Now that we have made the functional forms for each of our parameters, we'll sample all at once! As before, we need to define a overall log-likelihood function to pass into `emcee`. A large benefit of using the log-likelihood is that one can combine log-likelihoods linearly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddfcaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_Ltot(theta, nu, S, Sres, Serr):\n",
    "    T, y, mu = theta\n",
    "    T = T*u.K \n",
    "    return log_LBB(T, nu, S, Serr) + log_Ly(y, nu, Sres, Serr) + log_Lmu(mu, nu, Sres, Serr)\n",
    "\n",
    "pos_tot = [T_ini.value, y_ini, mu_ini] + 1e-6*np.random.randn(32, 3)\n",
    "nwalkers_tot, ndim_tot = pos_tot.shape\n",
    "\n",
    "sampler_tot = mc.EnsembleSampler(nwalkers_tot, ndim_tot, log_Ltot, args = (firas_freq, firas[\"monopole\"], firas[\"res\"], firas[\"sigma\"]))\n",
    "sampler_tot.run_mcmc(pos_tot, chain_len, progress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb241064-bb28-46ea-9157-3ab02963d4ae",
   "metadata": {},
   "source": [
    "As before, let's plot the chains for each of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d277bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler_tot.get_chain()\n",
    "\n",
    "fig, axes = plt.subplots(sharex=True, nrows=3)\n",
    "labels=[r'$T_0$', r'$y$', r'$\\mu$']\n",
    "for i in range(3):\n",
    "    axes[i].plot(samples[50:, :, i], \"k\", alpha = 0.3)\n",
    "    axes[i].set_ylabel(labels[i])\n",
    "    axes[i].yaxis.set_label_coords(-0.1, 0.5)\n",
    "axes[2].set_xlabel(\"sample number\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5547a",
   "metadata": {},
   "source": [
    "Again, use the autocorrelation length to estimate the burnin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18678a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sampler_tot.get_chain()\n",
    "\n",
    "fig, axes = plt.subplots(sharex=True, nrows=3)\n",
    "labels=[r'$T_0$', r'$y$', r'$\\mu$']\n",
    "for i in range(3):\n",
    "    axes[i].plot()\n",
    "    axes[i].set_ylabel(labels[i])\n",
    "    axes[i].yaxis.set_label_coords(-0.1, 0.5)\n",
    "axes[2].set_xlabel(\"sample number\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36133312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flat_samples = sampler_tot.get_chain(discard = , thin = int(tau_y), flat = True)\n",
    "txt = \"\\mathrm{{{3}}} = {0:.7f}_{{-{1:.6f}}}^{{{2:.6f}}}\"\n",
    "labels = [\"T_0\", \"y\", \"\\mu\"]\n",
    "for i in range(ndim_tot):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt_0 = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    display(Math(txt_0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4d4b87-6fca-4894-84b7-a56b1d56661d",
   "metadata": {},
   "source": [
    "It is definitely useful to get an idea of how good of a fit our model is to our data, so we will define a simple sum of least-square function to evaluate. Luckily, the log-likelihood function that we've defined for the model evaluation is already written, and can be re-used to define our goodness-of-fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96984e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chisq = np.zeros((flat_samples.shape[0], 1))\n",
    "for i in range(flat_samples.shape[0]):\n",
    "    theta = [flat_samples[i, 0], flat_samples[i, 1], flat_samples[i, 2]]\n",
    "    chisq[i] = log_Ltot(theta, firas_freq, firas[\"monopole\"], firas[\"res\"], firas[\"sigma\"])*-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843ad96-98fe-4550-9d23-91329b50265a",
   "metadata": {},
   "source": [
    "A good way to check how correlated or degenerate parameters are can be to plot corner plots ([python package](https://corner.readthedocs.io/en/latest/pages/quickstart/)). So let's give that a try here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5d2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chisq.shape, flat_samples.shape)\n",
    "corner_data = np.concatenate((flat_samples[250:,:], chisq[250:,:]), axis = 1)\n",
    "corner(corner_data, show_titles = True, labels = [r\"T$_0$\", r\"$y$\", r\"$\\mu$\", r\"$\\chi^2$\"], title_fmt = \".3e\")\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b11c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mcmc = np.percentile(flat_samples[:, 1], 50)\n",
    "mu_mcmc = np.percentile(flat_samples[:, 2], 50)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(firas_freq, firas[\"res\"], \"k\", lw = 1)\n",
    "plt.plot(firas_freq, (func_mu(firas_freq, mu_mcmc)), color = 'xkcd:turquoise', ls = \"--\", label = \"fit (mu)\")\n",
    "plt.plot(firas_freq, (func_y(firas_freq, y_mcmc)), color = 'xkcd:orange', ls = \"-.\", label = \"fit (y)\")\n",
    "plt.ylim([-50, 50])\n",
    "plt.xlabel(r\"Frequency (s$^{-1}$)\")\n",
    "plt.ylabel(\"Residual intensity (kJy/sr)\")\n",
    "plt.title(\"Fits to residuals\")\n",
    "plt.tight_layout()\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4da0dc",
   "metadata": {},
   "source": [
    "### Final consistency check\n",
    "\n",
    "We have not yet currently derived $y$-distortions or $\\mu$-distortions, so upper limits may be more appropriate to fit for. How would you report the results as upper limits rather than measurements centered around zeros?\n",
    "\n",
    "\n",
    "As a second point, the limits we derived are much tighter than the official limits. What are some potential sources of this difference? (There are many correct answers to this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac71f1",
   "metadata": {},
   "source": [
    "*I hypothesisize that...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
